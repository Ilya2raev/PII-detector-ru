{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9e606c0f584419684e0819397ae481f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3970887738b7464e9c1e2421a1ed06e4",
              "IPY_MODEL_87effd14739e4f68bdd4a55cfd6c01e9",
              "IPY_MODEL_0db1cf5e2c7046e18a2835bd1f6a04a1"
            ],
            "layout": "IPY_MODEL_ded28ac38662424585443d6a2006264f"
          }
        },
        "3970887738b7464e9c1e2421a1ed06e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c43bc170cc4757af5b672fb22aea75",
            "placeholder": "​",
            "style": "IPY_MODEL_f06876a3bf874f2fb9d243a43e56071e",
            "value": "100%"
          }
        },
        "87effd14739e4f68bdd4a55cfd6c01e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2167a439a5cf4cb5b35a8d154e68333a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a34f4f75b14a57877b0db796cb6609",
            "value": 1
          }
        },
        "0db1cf5e2c7046e18a2835bd1f6a04a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8904e075b4174d37b0baaae34c420f81",
            "placeholder": "​",
            "style": "IPY_MODEL_68b0e3ed04e4479cbd41f377813933f9",
            "value": " 1/1 [05:29&lt;00:00, 329.22s/it]"
          }
        },
        "ded28ac38662424585443d6a2006264f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c43bc170cc4757af5b672fb22aea75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06876a3bf874f2fb9d243a43e56071e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2167a439a5cf4cb5b35a8d154e68333a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a34f4f75b14a57877b0db796cb6609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8904e075b4174d37b0baaae34c420f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b0e3ed04e4479cbd41f377813933f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/IlyaGusev/saiga_mistral_7b_gguf/resolve/main/model-q4_K.gguf\n",
        "!wget https://raw.githubusercontent.com/IlyaGusev/rulm/master/self_instruct/src/interact_mistral_llamacpp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzLnzI3lmjxu",
        "outputId": "5fc18655-3654-49d3-af7f-a87fd62d50df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 15:22:40--  https://huggingface.co/IlyaGusev/saiga_mistral_7b_gguf/resolve/main/model-q4_K.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.74, 3.163.189.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/79/b3/79b3fc4694b2c3a22273003a1de570f145c14f0586c212c28c28e302adf5d3d6/2798f33ff63c791a21f05c1ee9a10bc95630b17225c140c197188a3d5cf32644?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-q4_K.gguf%3B+filename%3D%22model-q4_K.gguf%22%3B&Expires=1708528960&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODUyODk2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83OS9iMy83OWIzZmM0Njk0YjJjM2EyMjI3MzAwM2ExZGU1NzBmMTQ1YzE0ZjA1ODZjMjEyYzI4YzI4ZTMwMmFkZjVkM2Q2LzI3OThmMzNmZjYzYzc5MWEyMWYwNWMxZWU5YTEwYmM5NTYzMGIxNzIyNWMxNDBjMTk3MTg4YTNkNWNmMzI2NDQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=GATrjfd9WsGSHtP-FQLUbwGYwPwoVScKcpsmZ42dAINnbX2c1MIF%7EY-0D9ezUNvH1XecdE1ZA34LiDyitHZU23uS13skQeFBWirIAqH-a2tdHcG9oewbCBNacLHGPvUvblhdZowRN9Snw0eT%7ExBfoP-GwvEBTWHVrKnMaSIeIBCSOezg-BXBFkk0qBune0BOUiul3aoU%7E0a81yWCS1UsRyrklvrMGfr4eelu-V6lXMhfncmOcJ6dzjJsYJq8oEYBI4Qp6oWyzQuXRrHD0RS1c9lXXa3mFP%7EPdoPI38S9lLiPsHC0LS832%7EmINDfRxIK32thm3rpxZjPG4j0grfjjJA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-02-18 15:22:40--  https://cdn-lfs.huggingface.co/repos/79/b3/79b3fc4694b2c3a22273003a1de570f145c14f0586c212c28c28e302adf5d3d6/2798f33ff63c791a21f05c1ee9a10bc95630b17225c140c197188a3d5cf32644?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-q4_K.gguf%3B+filename%3D%22model-q4_K.gguf%22%3B&Expires=1708528960&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODUyODk2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83OS9iMy83OWIzZmM0Njk0YjJjM2EyMjI3MzAwM2ExZGU1NzBmMTQ1YzE0ZjA1ODZjMjEyYzI4YzI4ZTMwMmFkZjVkM2Q2LzI3OThmMzNmZjYzYzc5MWEyMWYwNWMxZWU5YTEwYmM5NTYzMGIxNzIyNWMxNDBjMTk3MTg4YTNkNWNmMzI2NDQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=GATrjfd9WsGSHtP-FQLUbwGYwPwoVScKcpsmZ42dAINnbX2c1MIF%7EY-0D9ezUNvH1XecdE1ZA34LiDyitHZU23uS13skQeFBWirIAqH-a2tdHcG9oewbCBNacLHGPvUvblhdZowRN9Snw0eT%7ExBfoP-GwvEBTWHVrKnMaSIeIBCSOezg-BXBFkk0qBune0BOUiul3aoU%7E0a81yWCS1UsRyrklvrMGfr4eelu-V6lXMhfncmOcJ6dzjJsYJq8oEYBI4Qp6oWyzQuXRrHD0RS1c9lXXa3mFP%7EPdoPI38S9lLiPsHC0LS832%7EmINDfRxIK32thm3rpxZjPG4j0grfjjJA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.94.23, 108.138.94.122, 108.138.94.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.94.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4368450336 (4.1G) [binary/octet-stream]\n",
            "Saving to: ‘model-q4_K.gguf’\n",
            "\n",
            "model-q4_K.gguf     100%[===================>]   4.07G  99.2MB/s    in 39s     \n",
            "\n",
            "2024-02-18 15:23:19 (108 MB/s) - ‘model-q4_K.gguf’ saved [4368450336/4368450336]\n",
            "\n",
            "--2024-02-18 15:23:19--  https://raw.githubusercontent.com/IlyaGusev/rulm/master/self_instruct/src/interact_mistral_llamacpp.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1774 (1.7K) [text/plain]\n",
            "Saving to: ‘interact_mistral_llamacpp.py’\n",
            "\n",
            "interact_mistral_ll 100%[===================>]   1.73K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-18 15:23:19 (5.66 MB/s) - ‘interact_mistral_llamacpp.py’ saved [1774/1774]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hxjCdLBomU8h"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install llama-cpp-python\n",
        "!pip install faker\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install cohere\n",
        "!pip install accelerate\n",
        "!pip install huggingface-hub\n",
        "!pip install auto-gptq\n",
        "!pip install optimum\n",
        "!pip install fire"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "from llama_cpp import Llama\n",
        "from tqdm.auto import tqdm\n",
        "from faker import Faker\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ayhoTAIsmhm2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"/content/model-q4_K.gguf\"\n",
        "llm = Llama(\n",
        "  model_path=model_path,\n",
        "  n_ctx=2048,\n",
        "  n_gpu_layers=-1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6joCM06miKx",
        "outputId": "b9d5fd91-6494-4989-a6d7-d029509ee08a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /content/model-q4_K.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = models\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32002\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = models\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
            "...............................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =    13.01 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   160.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'models', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def randomword(length):\n",
        "   \"\"\"Generate random string of length {length}\n",
        "      in order to create the document id\"\"\"\n",
        "   letters = string.ascii_lowercase\n",
        "   return ''.join(random.choice(letters) for i in range(length))\n",
        "\n",
        "def generate_address():\n",
        "    \"\"\"Generates a random Russian address with Faker.\n",
        "       Might be expanded for the sake of diversity.\"\"\"\n",
        "    language = \"ru_RU\"\n",
        "    fake = Faker(language)\n",
        "    return fake.address()"
      ],
      "metadata": {
        "id": "8Z8gxVrSnPzn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "    Ты живешь по адресу {address}.\n",
        "    Тебе необходимо написать короткое эссе про твой адрес.\n",
        "    Пожлауйста, напиши сначала о том, где ты живешь и почему тебе нравится или не нравится там жить.\n",
        "    Затем расскажи подробности про свое любимое место в мире, и где оно находится.\n",
        "    НЕ ДАВАЙ НИКАКУЮ ЛИЧНУЮ ИНФОРМАЦИЮ О СЕБЕ КРОМЕ АДРЕСА.\n",
        "\"\"\".replace(\"\\n \", \"\")\n",
        "\n",
        "for i in tqdm(range(1)):\n",
        "    # Get document ID\n",
        "    id = randomword(12)\n",
        "    # Get address\n",
        "    address = generate_address()\n",
        "    # Fill in prompt\n",
        "    prompt_ = prompt.format(address=address)\n",
        "    # Replace duplicate whitespaces\n",
        "    prompt_ = re.sub(\" +\", \" \", prompt_)\n",
        "    # Fill in Saiga template\n",
        "    command = f\"<s>[INST] {prompt_} [/INST]\"\n",
        "    output = llm(\n",
        "        command,\n",
        "        max_tokens=768,\n",
        "        stop=[\"</s>\"],\n",
        "        echo=True,\n",
        "        temperature=0.6\n",
        "    )\n",
        "\n",
        "    # Collect generated PII to label\n",
        "    label_dict={\"STREET_ADDRESS\": [address]}\n",
        "\n",
        "    # Collect data and append\n",
        "    data=[id, output[\"choices\"][0][\"text\"].split(\"[/INST]\")[1], label_dict]\n",
        "    pd.DataFrame(\n",
        "        [data],\n",
        "        columns=[\"document\", \"text\", \"label_dict\"]\n",
        "    ).to_csv(\"pii_address.csv\", mode=\"a\", header=False, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "f9e606c0f584419684e0819397ae481f",
            "3970887738b7464e9c1e2421a1ed06e4",
            "87effd14739e4f68bdd4a55cfd6c01e9",
            "0db1cf5e2c7046e18a2835bd1f6a04a1",
            "ded28ac38662424585443d6a2006264f",
            "b1c43bc170cc4757af5b672fb22aea75",
            "f06876a3bf874f2fb9d243a43e56071e",
            "2167a439a5cf4cb5b35a8d154e68333a",
            "58a34f4f75b14a57877b0db796cb6609",
            "8904e075b4174d37b0baaae34c420f81",
            "68b0e3ed04e4479cbd41f377813933f9"
          ]
        },
        "id": "D_WYHg7Im31q",
        "outputId": "f369028b-a27e-4530-ee61-3e25334233d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9e606c0f584419684e0819397ae481f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   95545.10 ms\n",
            "llama_print_timings:      sample time =     241.84 ms /   328 runs   (    0.74 ms per token,  1356.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =   95544.58 ms /   189 tokens (  505.53 ms per token,     1.98 tokens per second)\n",
            "llama_print_timings:        eval time =  231722.05 ms /   327 runs   (  708.63 ms per token,     1.41 tokens per second)\n",
            "llama_print_timings:       total time =  329082.28 ms /   516 tokens\n"
          ]
        }
      ]
    }
  ]
}